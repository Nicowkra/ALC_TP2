{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c0cbb93-2880-4750-975d-11cce9f6b12c",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 2 - Matrices Insumo-Producto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e274a5-6e2e-44fd-93bc-3425096cda3a",
   "metadata": {},
   "source": [
    "## Imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf901cec-77d4-4642-8732-e84bece85e68",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DBSCAN\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display, HTML\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunciones\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mf\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfuncionesTP1\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mftp1\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\Facultad\\ALC\\ALC_TP2\\funciones.py:126\u001b[0m\n\u001b[0;32m    122\u001b[0m     V \u001b[38;5;241m=\u001b[39m V[:, idx]\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m D, V, X, m\n\u001b[1;32m--> 126\u001b[0m D, V, X, m \u001b[38;5;241m=\u001b[39m \u001b[43mcalculoACP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA1\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\Facultad\\ALC\\ALC_TP2\\funciones.py:112\u001b[0m, in \u001b[0;36mcalculoACP\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculoACP\u001b[39m(data):\n\u001b[0;32m    111\u001b[0m     d, n \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m--> 112\u001b[0m     m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Asegúrate de que m sea un array de numpy\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     X \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mtile(m\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;28mlen\u001b[39m(m), \u001b[38;5;241m1\u001b[39m)), (\u001b[38;5;241m1\u001b[39m, n))  \u001b[38;5;66;03m# Usa data.values para obtener el array de numpy\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     Mcov \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(X, X\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;241m/\u001b[39m n  \u001b[38;5;66;03m# Covariance Matrix\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg as LA\n",
    "import scipy.linalg as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import funciones as f\n",
    "import funcionesTP1 as ftp1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881e9b90",
   "metadata": {},
   "source": [
    "## Consigna 2 - Graficamos los vectores $a_1$ y $a_2$, definidos con un tamaño de 250."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a47fd5",
   "metadata": {},
   "source": [
    "Creamos las matrices $A_1$ y $A_2$ tal como se describen en la consiga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "935500fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz A1:\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatriz A1:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mf\u001b[49m\u001b[38;5;241m.\u001b[39mA1)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatriz A2:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(f\u001b[38;5;241m.\u001b[39mA2)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Matriz A1:\\n\")\n",
    "print(f.A1)\n",
    "print(\"Matriz A2:\\n\")\n",
    "print(f.A2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294e8ad0",
   "metadata": {},
   "source": [
    "### Gráfica de la Norma del Vector por Posición\n",
    "\n",
    "Realizamos el gráfico de puntos para cada posición i del vector, utilizando la función `graficarVector(matriz, tamaño), que devuelve un gráfico correspondiente.\n",
    "\n",
    "La función `graficarVector` invoca a `vectorDeA_n`. Esta última calcula un vector donde cada posición i del vector representa la norma 2 de la matriz elevada a la potencia i:\n",
    "\n",
    "posición i del vector: $\\| A^i \\|_2$\n",
    "\n",
    "La función `vectorDeA_n(n, matrizOriginal)` devuelve un vector de dimensión n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26adbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.graficarVector(f.A1, 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0941e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.graficarVector(f.A2, 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40046716",
   "metadata": {},
   "source": [
    "A partir de lo demostrado en el punto 1, si una matriz tiende a cero en un límite específico, su norma 2 también tenderá a cero en ese mismo límite, dado que sus elementos se vuelven cada vez más pequeños. Esto implica que las combinaciones lineales que representan los valores singulares de la matriz también disminuirán en magnitud. Sin embargo, si la matriz contiene algunos elementos no nulos, aunque sean pequeños, estos podrían influir en el valor singular más grande, lo que podría alterar la convergencia esperada.\n",
    "\n",
    "Considerando estas condiciones y excepciones, podemos inferir que, en principio, la matriz $A_2$ parece converger, ya que su norma 2 se aproxima al cero. En contraste, la matriz $A_1$ no muestra signos de convergencia hacia cero después de 250 iteraciones, lo que sugiere que este número de iteraciones podría no ser suficiente para determinar su convergencia. Es importante tener en cuenta que la convergencia no solo depende de si los elementos de la matriz se acercan a cero, sino también de la composición global y la distribución de los valores dentro de la matriz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe006c4-bd7b-4465-ba1e-8c9f994b9f37",
   "metadata": {},
   "source": [
    "## Consigna 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09475347",
   "metadata": {},
   "source": [
    "### Implementación del método de la potencia para las matrices $A_1$ y $A_2$\n",
    "\n",
    "Esta función recibe un vector inicial $v_0$ y multiplica la matriz A por $v_0$ en la primera iteración. El resultado se almacena y, de manera recursiva, se calculan los siguientes estados durante k iteraciones, normalizando el vector en cada paso para evitar un crecimiento excesivo y mantener la dirección del cambio. De este modo, se obtiene el autovector asociado.\n",
    "\n",
    "La función `metodoPotencia(A, v, k)` devuelve el mayor autovalor y su autovector correspondiente. El cálculo se realiza mediante la siguiente ecuación:\n",
    "\n",
    "$autovalor = \\frac{(v^T A v)}{(v^T v)}$\n",
    "\n",
    "Adicionalmente, utilizando el método de Monte Carlo, generamos 250 vectores iniciales $v_0$ aleatorios con valores entre 0 y 1000. Para cada uno de estos vectores, aplicamos el método de la potencia con k = 8. También calculamos el promedio de los autovalores obtenidos con cada $v_0$ y su desviación estándar.\n",
    "\n",
    "La función `monteCarlo(A)` devuelve el promedio del mayor autovalor calculado en cada iteración, junto con su desviación estándar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4ffc63-5a06-4c36-8c56-25ad67cb8aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prom_a1 ,DE_a1 = f.monteCarlo(f.A1) \n",
    "prom_a2 ,DE_a2 = f.monteCarlo(f.A2) \n",
    "tabla = pd.DataFrame({\"Promedio\":[prom_a1,prom_a2],\"Desvio Estandar\":[DE_a1,DE_a2]})\n",
    "tabla.index = [\"A1\",\"A2\"]\n",
    "tabla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb6bbaa",
   "metadata": {},
   "source": [
    "Se ejecutó el método de la potencia un total de 8 veces, observándose que los valores presentan un pequeño desvío respecto al promedio, de aproximadamente $10^{-5}$ para la matriz $A_1$ y $10^{-4}$ para la matriz $A_2$. Con base en estos resultados, se concluye que el autovalor encontrado para la matriz $A_1$ es 1, mientras que para la matriz $A_2$ es 0.927.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1791f2e",
   "metadata": {},
   "source": [
    "## Consigna 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26024428",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrizConsigna4 = np.linalg.inv(np.identity(f.A1.shape[0]) - f.A1)\n",
    "\n",
    "f.graficarVector(matrizConsigna4, 10)\n",
    "f.vectorDeA_n(10, matrizConsigna4)\n",
    "\n",
    "##ESTA MAAAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accc0aa1-ed10-4c3d-9a3b-ab276f54ef11",
   "metadata": {},
   "source": [
    "## Consigna 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6747399d-97bf-4a06-a9e2-c9ec39909177",
   "metadata": {},
   "source": [
    "- Creo $ A^{pp} y A^{nn} $ como en el TP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b251ee5a-bf9f-400c-8f25-814e92df5c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz = pd.read_excel(\"matriz.xlsx\", sheet_name =\"LAC_IOT_2011\",)\n",
    "Nic_col = []    \n",
    "Pry_col = []\n",
    "for i in range(1,41): #Crea la lista de columnas a filtrar\n",
    "    Nic_col.append('NICs'+str(i))\n",
    "    Pry_col.append('PRYs'+str(i))\n",
    "    \n",
    "Pry = matriz[matriz[\"Country_iso3\"] == \"PRY\"] # Crea la tabla con filas de PRY\n",
    "Nic = matriz[matriz[\"Country_iso3\"] == \"NIC\"] # Crea la tabla con filas de NIC\n",
    "# Crea matrices intra-regionales\n",
    "Pry_int= Pry.loc[:,Pry_col] \n",
    "Nic_int = Nic.loc[:,Nic_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ac4ac7-03ec-4b6c-8caa-8b58512a49a2",
   "metadata": {},
   "source": [
    "- uso la funcion de metodo de la potencia con un vector aleatorio y lo comparo con los autovalores dados por __numpy.linalg.eig__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15bd577-607e-49e6-bb6b-44a24eab058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_Pry = np.random.randint(0,1000,size = Pry_int.shape[0]) #Creo vector aleatorio\n",
    "aval_Pry,avect_Pry = f.metodoPotencia(Pry_int.to_numpy(),vect_Pry,250) #Uso metodo de la potencia\n",
    "eigval_Pry,eigvect_Pry = LA.eig(Pry_int.to_numpy())\n",
    "\n",
    "vect_Nic = np.random.randint(0,1000,size = Nic_int.shape[0])\n",
    "aval_Nic,avect_Nic = f.metodoPotencia(Nic_int.to_numpy(),vect_Nic,250)\n",
    "eigval_Nic,eigvect_Nic = LA.eig(Nic_int.to_numpy())\n",
    "\n",
    "tabla = pd.DataFrame({\"Aproximado\":[aval_Pry,aval_Nic],\"Real\":[eigval_Pry[0],eigval_Nic[0]]})\n",
    "tabla.index = [\"Pry\",\"Nic\"]\n",
    "tabla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f64034",
   "metadata": {},
   "source": [
    "## Consigna 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d27e042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb38a87a-0bf5-4070-81dc-139fba2cb660",
   "metadata": {},
   "source": [
    "## Consigna 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5942751a-135d-4e1b-94b2-25b75a36d73b",
   "metadata": {},
   "source": [
    "<center></h1>Creo C dada por:</center></h1>\n",
    "\n",
    "<center></h1>$C = {\\overline{A^{pp}}}^{t} \\, \\overline{A^{pp}}/(40-1)$</center></h1>\n",
    "\n",
    "<center></h1>donde  $\\; \\overline{A^{pp}} = E_{40}A^{pp}$, y $E_{n}$ es dada por: $E_{n} = I_{n} - \\frac{1}{n}ee^{t}$</center></h1>\n",
    "\n",
    "<center></h1>y $e \\in \\mathbb{R}^{n}$ es un vector columna de todos 1 </center></h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3795eb-4bd7-419e-8ca0-ab2b76911d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = Pry_int.shape[0]\n",
    "Id = np.identity(n)\n",
    "e = np.ones(n)\n",
    "En = Id - 1/n * (np.atleast_2d(e).T @ np.atleast_2d(e))\n",
    "C = ((En @ Pry_int.to_numpy()).T @ (En @ Pry_int.to_numpy()))/(40-1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caccd604-2db7-4241-97bc-469efa79e7c8",
   "metadata": {},
   "source": [
    "Defino la funcion para crear un vector aleatorio de norma 1 y una funcion usando el algoritmo de Hotelling, donde se itera de la siguiente forma:\n",
    "$$\n",
    "x_{1} = Cx_{0} / \\| Cx_{0} \\|\n",
    "$$\n",
    "$$\n",
    "x_{k+1} = Cx_{k} / \\| Cx_{k} \\|\n",
    "$$\n",
    "Para encontrar el primer autovector con maximo autovalor.  \n",
    "- Para obtener el autovalor se usa el coeficiente de Rayleigh $ \\lambda = \\frac{v_{1}^{t}Cv_{1}}{v_{1}^{t}v_{1}} $  \n",
    "- Si tiene autovalor positivo, el criterio de parada va a ser cuando $\\| x_{k+1}^{t}\\ - x_{k} \\|_{2} <$ _valor_ , donde _valor_ es 1e-6.  \n",
    "- En cambio si su autovalor es negativo, se usa como criterio cuando $ |\\lambda_{k}| - |\\lambda_{k+1}|$ < _valor_ , esto se debe a que cuando el autovalor es negativo, el autovector va a oscilar entre un vector y su opuesto, por lo que la norma de la diferencia siempre va a ser 2. En cambio este segundo criterio si funciona ya que el autovalor si converge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b666c912-8e78-400a-9115-dec54d15b175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create(n): \n",
    "     x = np.random.normal(size=n)\n",
    "     x -= x.mean()\n",
    "     return x / np.linalg.norm(x)\n",
    "    \n",
    "def Hotelling(A,v,valor):\n",
    "    while True:\n",
    "        v_prev = v\n",
    "        vEstrella_prev = f.vectorEstrella(v_prev)\n",
    "        aval_prev = (vEstrella_prev @ A @ v_prev) / (vEstrella_prev @ v_prev)\n",
    "        \n",
    "        v = A @ v\n",
    "        v = v / np.linalg.norm(v)\n",
    "\n",
    "        vEstrella = f.vectorEstrella(v)\n",
    "        aval = (vEstrella @ A @ v) / (vEstrella @ v)\n",
    "        res = vEstrella - v_prev\n",
    "        \n",
    "        if (aval >=0) and (np.linalg.norm(res,2) < valor):\n",
    "            return aval,v \n",
    "            \n",
    "        elif (aval < 0) and ((abs(aval)-abs(aval_prev)) < valor):\n",
    "            return aval,v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86304e99-ef1f-4dce-b55c-855aeeabc492",
   "metadata": {},
   "source": [
    "Saco $v_{1}$ y $\\lambda_{1}$ con la funcion Hotelling y comparo con lo dado por __numpy.linalg.eig__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b95e3ed-3e03-49f2-b6b3-a59874793d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "valor = 1e-10\n",
    "vect = create(n)\n",
    "avalH, vectH = Hotelling(C,vect,valor)\n",
    "eigval, eigvect = LA.eig(C)\n",
    "tabla = pd.DataFrame({\"Aproximado\":[vectH,avalH],\"Real\":[eigvect[:,0],eigval[0]]})\n",
    "tabla.index = [\"Autovector\",\"Autovalor\"]\n",
    "display(HTML(tabla.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff29463-1927-4692-85a6-a60b9ee68624",
   "metadata": {},
   "source": [
    "Para encontrar $v_{2}$ y $\\lambda_{2}$, se necesita encontrar $C'$, dada por:\n",
    "$$\n",
    "C' = C - \\lambda_{1}v_{1}v_{1}^{t}\n",
    "$$\n",
    "Se vuelve a calcular Hotelling con $C'$ y otro vector aleatorio de norma 1 y se comparan los resultados con los dados por __numpy.linalg.eig__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d1242f-c350-48d0-8701-c0eda150bd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectHEstrella = f.vectorEstrella(vectH)\n",
    "C2 = C - avalH * (vectH @ vectHEstrella)\n",
    "vect2 = create(n)\n",
    "avalH2, vectH2 = Hotelling(C2,vect2,valor)\n",
    "eigval2,eigvect2 = LA.eig(C2)\n",
    "tabla = pd.DataFrame({\"Aproximado\":[vectH2,avalH2],\"Real\":[eigvect2[:,0],eigval2[0]]})\n",
    "tabla.index = [\"Autovector\",\"Autovalor\"]\n",
    "display(HTML(tabla.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f9ed73-2fd8-4260-9960-7a7e46b2ffc0",
   "metadata": {},
   "source": [
    "## Consigna 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45ac85d-64e4-4b40-8d7a-824e16fbb2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proyectar(A,v1,v2):\n",
    "    V = np.column_stack((v1,v2))\n",
    "    return A @ V\n",
    "\n",
    "Arr_proyectada = proyectar(Pry_int.to_numpy(),vectH,vectH2)\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)  # Busco clusters con KMeans\n",
    "clusters = kmeans.fit_predict(Arr_proyectada)\n",
    "\n",
    "df_clusters = pd.DataFrame(Arr_proyectada, columns=['v1', 'v2'])\n",
    "df_clusters['Cluster'] = clusters\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(data=df_clusters, x='v1', y='v2', hue='Cluster', palette='viridis', s=100)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b8bebf",
   "metadata": {},
   "source": [
    "## Consigna 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9801e55",
   "metadata": {},
   "source": [
    "El analisis lo vamos a llevar a cabo sobre la matriz creada en el TP1, creada con las matrices regionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968bbc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = ftp1.crearMatrizA()\n",
    "H = A @ np.linalg.inv(np.identity(A.shape[0]) - A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5103a4a",
   "metadata": {},
   "source": [
    "Realizamos el calculo de ACP por el metodo de la potencia implementado en la consigna 7. Lo realizamos de manera iterativa para poder conseguir la matriz V, base de autovectores. Pero como solo utilizaremos los primeros dos autovectores, no calculamos la V completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e858539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def centrarDatos(matriz):\n",
    "    # Centramos los datos\n",
    "    d, n = matriz.shape\n",
    "    m = np.mean(matriz.values, axis=1)  # Asegúrate de que m sea un array de numpy\n",
    "\n",
    "    X = matriz.values - np.tile(m.reshape((len(m), 1)), (1, n))  # Usa data.values para obtener el array de numpy\n",
    "    Mcov = np.dot(X, X.T) / n  # Covariance Matrix\n",
    "    return X, Mcov\n",
    "\n",
    "def PrimerasNColumnasDeV_con_mP(matriz, n):\n",
    "    d, _ = matriz.shape\n",
    "    V = []  # Lista para almacenar los autovectores\n",
    "    matriz_iterada = matriz.copy()\n",
    "\n",
    "    for i in range(n):\n",
    "        # Crear un vector inicial aleatorio\n",
    "        vect = create(d)\n",
    "        \n",
    "        # Usamos Hotelling para obtener el autovector\n",
    "        aval, vect = Hotelling(matriz_iterada, vect, valor)\n",
    "        \n",
    "        # Normalizamos el autovector\n",
    "        vectEstrella = f.vectorEstrella(vect)\n",
    "        \n",
    "        # Actualizamos la matriz iterada (descontamos el componente encontrado)\n",
    "        matriz_iterada -= aval * np.outer(vect, vectEstrella)\n",
    "        \n",
    "        # Añadimos el autovector encontrado a la lista\n",
    "        V.append(vect)\n",
    "    \n",
    "    return np.array(V).T  # Devolvemos las primeras N columnas de V como una matriz\n",
    "\n",
    "X, Mcov = centrarDatos(H)\n",
    "V1 = PrimerasNColumnasDeV_con_mP(Mcov,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582d3b90",
   "metadata": {},
   "source": [
    "Realizamos un grafico proyectando los datos en 2-D, proyectando los datos en las dos direcciones de mayor cambio. \n",
    "Ademas, agregar el metodo de agrupamiento K-means al grafico, con n_clusters = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160ba008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proyectar los datos en las dos primeras componentes principales\n",
    "X_reducido = X.T @ V[:, :2]  # Transponer X para que las observaciones sean filas\n",
    "\n",
    "# Aplicar K-means para encontrar clusters\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)  # Puedes ajustar el número de clusters\n",
    "clusters = kmeans.fit_predict(X_reducido)\n",
    "\n",
    "# Convertir el resultado a un DataFrame para facilitar la visualización\n",
    "df_clusters = pd.DataFrame(X_reducido, columns=['Componente 1', 'Componente 2'])\n",
    "df_clusters['Cluster'] = clusters\n",
    "\n",
    "# Graficar los resultados\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.scatterplot(data=df_clusters, x='Componente 1', y='Componente 2', hue='Cluster', palette='viridis', s=100)\n",
    "plt.title('Clusters en el espacio de componentes principales')\n",
    "plt.xlabel('Componente Principal 1')\n",
    "plt.ylabel('Componente Principal 2')\n",
    "plt.legend(title='Cluster')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166ef004",
   "metadata": {},
   "source": [
    "Vemos que el analisis de K-means no es el ideal ya que tenemos outliers, y ademas los datos no se llega a identificar grupos ocultos en los datos o intuidos, sino que la densidad de distribucion de los mismos.\n",
    "\n",
    "Incluso realizamos un analisis de DBSCAN que es robusto detectando outliers y puede encontrar clusters con formas geometricas arbitrarias, pero no obtenemos mejores resultados. \n",
    "El analisis de DBCAN identifico un solo cluster(el asignado con el numero cero) y el resto outliers (los valores violetas en -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634d3404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supongamos que ya tienes X_reducido de tu análisis PCA\n",
    "# Ajustar y aplicar DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "clusters_dbscan = dbscan.fit_predict(X_reducido)\n",
    "\n",
    "# Convertir el resultado a un DataFrame para facilitar la visualización\n",
    "df_dbscan = pd.DataFrame(X_reducido, columns=['Componente 1', 'Componente 2'])\n",
    "df_dbscan['Cluster'] = clusters_dbscan\n",
    "\n",
    "# Graficar los resultados de DBSCAN\n",
    "plt.figure(figsize=(6, 4))\n",
    "palette = sns.color_palette(\"viridis\", as_cmap=True)\n",
    "sns.scatterplot(data=df_dbscan, x='Componente 1', y='Componente 2', hue='Cluster', palette=palette, s=100)\n",
    "plt.title('Clusters en el espacio de componentes principales (DBSCAN)')\n",
    "plt.xlabel('Componente Principal 1')\n",
    "plt.ylabel('Componente Principal 2')\n",
    "plt.legend(title='Cluster')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Análisis de ruido\n",
    "n_noise = np.sum(clusters_dbscan == -1)\n",
    "total_points = df_dbscan.shape[0]\n",
    "print(f\"Número de puntos ruido: {n_noise} de {total_points} ({(n_noise / total_points) * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "05a3f40d",
   "metadata": {},
   "source": [
    "Realizamos un \"zoom\" al grafico anterior quitando los dos outliers mas notables, para ver si podemos diferenciar mejor algun tipo de patron interno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95343c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Contar los puntos en cada cluster\n",
    "cluster_counts = df_dbscan['Cluster'].value_counts()\n",
    "\n",
    "# Paso 2: Identificar clusters robustos (aquellos con más de una observación)\n",
    "clusters_to_keep = cluster_counts[cluster_counts > 1].index\n",
    "\n",
    "# Paso 3: Filtrar el DataFrame para mantener solo los clusters robustos\n",
    "df_filtered = df_dbscan[df_clusters['Cluster'].isin(clusters_to_keep)]\n",
    "\n",
    "# Paso 4: Graficar los clusters sin los outliers\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.scatterplot(data=df_filtered, x='Componente 1', y='Componente 2', hue='Cluster', palette='viridis', s=100)\n",
    "plt.title('Clusters sin Outliers')\n",
    "plt.xlabel('Componente Principal 1')\n",
    "plt.ylabel('Componente Principal 2')\n",
    "plt.legend(title='Cluster')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdd480c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a5beb11",
   "metadata": {},
   "source": [
    "### Consigna 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d65986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distanciaOrigen(punto):\n",
    "    return np.sqrt(punto[0]**2 + punto[1]**2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4931d914",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
